import numpy as np
import pandas as pd
data = pd.read_csv("loan_approval_dataset.csv")
data.info()
data.head()
data.describe()
# Remove leading/trailing whitespace from column names
data.columns = data.columns.str.strip()
#data.drop(columns=['loan_id'], inplace=True)
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
data['education'] = le.fit_transform(data['education'])
data['self_employed'] = le.fit_transform(data['self_employed'])
data['loan_status'] = le.fit_transform(data['loan_status'])  # Target: Approved=1, Rejected=0
print(dict(zip(le.classes_, le.transform(le.classes_))))
print(data.head())
print(data.info())

print(data.describe())


from google.colab import drive
drive.mount('/content/drive')

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Features and target
X = data.drop('loan_status', axis=1)
y = data['loan_status']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

#Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pandas as pd
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

print("\n Random Forest Classifier")
print("Accuracy:", accuracy_score(y_test, rf_preds))
print(confusion_matrix(y_test, rf_preds))
print(classification_report(y_test, rf_preds))

#Xgboost
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

print("\n Gradient Boosting Classifier")
print("Accuracy:", accuracy_score(y_test, gb_preds))
print(confusion_matrix(y_test, gb_preds))
print(classification_report(y_test, gb_preds))

#graph
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(10, 6))
sns.countplot(x='loan_status', data=data)
plt.title("Loan Status Distribution")
plt.xlabel("Loan Status")
plt.ylabel("Count")
plt.show()
plt.figure(figsize=(10, 6))

plt.figure(figsize=(10, 6))
sns.heatmap(data.corr(), annot=True,fmt='.2f', cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()
sns.boxplot(x='loan_status', y='income_annum',color='pink',data=data)
plt.title("Income vs Loan Status")
plt.xlabel("Loan Status")
plt.ylabel("Income")
plt.show()
from sklearn.ensemble import RandomForestClassifier
import numpy as np

model = RandomForestClassifier()
model.fit(X_train, y_train)

importances = model.feature_importances_
features = X.columns
indices = np.argsort(importances)

plt.figure(figsize=(10, 6))
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

sns.scatterplot(x='income_annum', y='loan_amount', hue='loan_status', data=data)
plt.title("Income vs Loan Amount")
plt.show()

